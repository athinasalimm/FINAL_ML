{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149a7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d3267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2cee98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.utils import filtrar_meses, verificar_columnas_y_tipos, estandarizar_nombres_columnas\n",
    "from src.utils import funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f16915",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test/test.csv\")\n",
    "test.to_csv(\"data/test/test_pr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658ab70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Columnas disponibles en el shapefile:\n",
      "Index(['id', 'objeto', 'nombre', 'comuna', 'perimetro_', 'area_metro',\n",
      "       'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "barrios_gdf = gpd.read_file(\"data/barrios/barrios.shp\")\n",
    "\n",
    "# Ver columnas reales\n",
    "print(\"üß© Columnas disponibles en el shapefile:\")\n",
    "print(barrios_gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e655dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Rutas de los datasets en orden descendente\n",
    "archivos = [\n",
    "    \"data/test/test_pr.csv\",\n",
    "]\n",
    "\n",
    "# Diccionario de estaciones √∫nicas: id_estacion -> (lat, lon)\n",
    "estaciones_dict = {}\n",
    "\n",
    "for path in archivos:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ö†Ô∏è Archivo no encontrado: {path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    for rol in [\"origen\", \"destino\"]:\n",
    "        for _, row in df.iterrows():\n",
    "            est_id = row[f\"id_estacion_{rol}\"]\n",
    "            lat = row[f\"lat_estacion_{rol}\"]\n",
    "            lon = row[f\"long_estacion_{rol}\"]\n",
    "\n",
    "            if pd.notna(est_id) and pd.notna(lat) and pd.notna(lon):\n",
    "                if est_id not in estaciones_dict:\n",
    "                    estaciones_dict[est_id] = (lat, lon)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81031353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estaciones = pd.DataFrame([\n",
    "    {\"id_estacion\": est_id, \"lat\": lat, \"lon\": lon}\n",
    "    for est_id, (lat, lon) in estaciones_dict.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06118c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enriquecido con barrios: test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Cargar shapefile de barrios\n",
    "barrios_gdf = gpd.read_file(\"data/barrios/barrios.shp\")\n",
    "\n",
    "if \"nombre\" in barrios_gdf.columns and \"barrio\" not in barrios_gdf.columns:\n",
    "    barrios_gdf = barrios_gdf.rename(columns={\"nombre\": \"barrio\"})\n",
    "\n",
    "# Crear GeoDataFrame desde df_estaciones (ya lo ten√©s construido)\n",
    "df_estaciones[\"geometry\"] = df_estaciones.apply(lambda row: Point(row[\"lon\"], row[\"lat\"]), axis=1)\n",
    "estaciones_gdf = gpd.GeoDataFrame(df_estaciones, geometry=\"geometry\", crs=barrios_gdf.crs)\n",
    "\n",
    "# Join espacial (punto dentro de pol√≠gono)\n",
    "estaciones_con_barrios = gpd.sjoin(estaciones_gdf, barrios_gdf, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Crear CSV (opcional)\n",
    "estaciones_con_barrios[[\"id_estacion\", \"lat\", \"lon\", \"barrio\"]].to_csv(\"data/estaciones_con_barrios.csv\", index=False)\n",
    "\n",
    "# Crear diccionario: id_estacion -> barrio\n",
    "mapa_barrio = estaciones_con_barrios.set_index(\"id_estacion\")[\"barrio\"].to_dict()\n",
    "\n",
    "# Sobrescribir manualmente los valores deseados\n",
    "mapa_barrio[111] = \"PUERTO MADERO\"\n",
    "mapa_barrio[541] = \"PALERMO\"\n",
    "\n",
    "path = \"data/test/test_pr.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df[\"barrio_origen\"] = df[\"id_estacion_origen\"].map(mapa_barrio)\n",
    "df[\"barrio_destino\"] = df[\"id_estacion_destino\"].map(mapa_barrio)\n",
    "df.to_csv(path, index=False)\n",
    "print(\"‚úÖ Enriquecido con barrios: test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3051cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# A√±os relevantes\n",
    "anios_recorridos = [2020, 2021, 2022, 2023, 2024]\n",
    "anios_usuarios_nuevos = [2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "# === 1. Cargar todos los usuarios que aparecen en recorridos ===\n",
    "usuarios_recorridos = []\n",
    "\n",
    "path_test = \"data/test/test_pr.csv\"\n",
    "if os.path.exists(path_test):\n",
    "    df_test = pd.read_csv(path_test, usecols=[\"id_usuario\"])\n",
    "    df_test = df_test.dropna().astype({\"id_usuario\": int})\n",
    "    df_test[\"a√±o_recorrido\"] = 2024  # Asignar a√±o de test\n",
    "    usuarios_recorridos.append(df_test)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ archivo de test\")\n",
    "\n",
    "df_usuarios_recorridos = pd.concat(usuarios_recorridos, ignore_index=True)\n",
    "\n",
    "\n",
    "usuarios_registrados = []\n",
    "path = f\"data/usuarios/processed/usuarios_ecobici_2024_limpio.csv\"\n",
    "if os.path.exists(path):\n",
    "    df = pd.read_csv(path, usecols=[\"ID_usuario\"])\n",
    "    df = df.dropna().astype({\"ID_usuario\": int})\n",
    "    usuarios_registrados.append(df)\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è No se encontr√≥ archivo de usuarios a√±o\")\n",
    "\n",
    "\n",
    "df_usuarios_registrados = pd.concat(usuarios_registrados, ignore_index=True)\n",
    "usuarios_2020_2024_set = set(df_usuarios_registrados[\"ID_usuario\"].unique())\n",
    "\n",
    "\n",
    "df_no_registrados = df_usuarios_recorridos[\n",
    "    ~df_usuarios_recorridos[\"id_usuario\"].isin(usuarios_2020_2024_set)\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f57b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\catal\\OneDrive\\Documents\\UDESA\\A√±oIII\\Machine Learning\\Proyecto_Final\\FINAL_ML\\modeling.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta)\n",
      "c:\\Users\\catal\\OneDrive\\Documents\\UDESA\\A√±oIII\\Machine Learning\\Proyecto_Final\\FINAL_ML\\modeling.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta)\n",
      "c:\\Users\\catal\\OneDrive\\Documents\\UDESA\\A√±oIII\\Machine Learning\\Proyecto_Final\\FINAL_ML\\modeling.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(ruta)\n",
      "Contando estaciones cercanas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 398/398 [00:11<00:00, 35.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar viajes\n",
    "df_viajes = pd.read_csv(\"data/test/test_pr.csv\")\n",
    "\n",
    "data_usuario = pd.read_csv(\"data/usuarios/processed/usuarios_ecobici_2024_limpio.csv\")\n",
    "df_filtrado = data_usuario[data_usuario[\"mes_alta\"] > 8].copy()\n",
    "df_filtrado.to_csv(\"data/usuarios/processed/usuarios_ecobici_2024_limpio_filtrado_test.csv\", index=False)\n",
    "df_usuarios = pd.read_csv(\"data/usuarios/processed/usuarios_ecobici_2024_limpio_filtrado_test.csv\")  # debe tener id_usuario, mes_alta, anio_alta, fecha_alta\n",
    "\n",
    "\n",
    "df_estaciones = pd.read_csv(\"data/estaciones_con_barrios.csv\")  # debe tener id_estacion, barrio, lat, lon\n",
    "from modeling import construir_dataset_modelado_v2\n",
    "\n",
    "df_modelado = construir_dataset_modelado_v2(df_viajes, df_usuarios, df_estaciones)\n",
    "df_modelado.to_csv(\"data/modelado/ds_modelado_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa8addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelado = pd.read_csv(\"data/modelado/ds_modelado_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b737efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido',\n",
      "       'id_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino',\n",
      "       'id_usuario', 'modelo_bicicleta', 'barrio_origen', 'barrio_destino',\n",
      "       'fecha_intervalo', 'hora_dia', 'dia_semana', 'es_finde',\n",
      "       'estacion_del_anio', 'edad_usuario', 'a√±o_alta', 'mes_alta',\n",
      "       'genero_FEMALE', 'genero_MALE', 'genero_OTHER', 'usuario_registrado',\n",
      "       'zona_destino_cluster', 'zona_origen_cluster',\n",
      "       'cantidad_estaciones_cercanas_destino',\n",
      "       'cantidad_estaciones_cercanas_origen', 'N_arribos_intervalo',\n",
      "       'N_salidas_intervalo'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_modelado.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c070da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa_estaciones = {\n",
    "    \"verano\": 1,\n",
    "    \"otono\": 2,\n",
    "    \"invierno\": 3,\n",
    "    \"primavera\": 4\n",
    "}\n",
    "\n",
    "df_modelado[\"estacion_del_anio\"] = df_modelado[\"estacion_del_anio\"].map(mapa_estaciones).astype(int)\n",
    "df_modelado[\"fecha_origen_recorrido\"] = pd.to_datetime(df_modelado[\"fecha_origen_recorrido\"], errors=\"coerce\")\n",
    "df_modelado[\"fecha_destino_recorrido\"] = pd.to_datetime(df_modelado[\"fecha_destino_recorrido\"], errors=\"coerce\")\n",
    "df_modelado[\"fecha_intervalo\"] = pd.to_datetime(df_modelado[\"fecha_intervalo\"], errors=\"coerce\")\n",
    "\n",
    "df_modelado[\"a√±o_origen\"] = df_modelado[\"fecha_origen_recorrido\"].dt.year\n",
    "df_modelado[\"mes_origen\"] = df_modelado[\"fecha_origen_recorrido\"].dt.month\n",
    "df_modelado[\"dia_origen\"] = df_modelado[\"fecha_origen_recorrido\"].dt.day\n",
    "df_modelado[\"hora_origen\"] = df_modelado[\"fecha_origen_recorrido\"].dt.hour\n",
    "df_modelado[\"minuto_origen\"] = df_modelado[\"fecha_origen_recorrido\"].dt.minute\n",
    "df_modelado[\"segundo_origen\"] = df_modelado[\"fecha_origen_recorrido\"].dt.second\n",
    "\n",
    "df_modelado[\"a√±o_destino\"] = df_modelado[\"fecha_destino_recorrido\"].dt.year\n",
    "df_modelado[\"mes_destino\"] = df_modelado[\"fecha_destino_recorrido\"].dt.month\n",
    "df_modelado[\"dia_destino\"] = df_modelado[\"fecha_destino_recorrido\"].dt.day\n",
    "df_modelado[\"hora_destino\"] = df_modelado[\"fecha_destino_recorrido\"].dt.hour\n",
    "df_modelado[\"minuto_destino\"] = df_modelado[\"fecha_destino_recorrido\"].dt.minute\n",
    "df_modelado[\"segundo_destino\"] = df_modelado[\"fecha_destino_recorrido\"].dt.second\n",
    "\n",
    "df_modelado[\"a√±o_intervalo\"] = df_modelado[\"fecha_intervalo\"].dt.year\n",
    "df_modelado[\"mes_intervalo\"] = df_modelado[\"fecha_intervalo\"].dt.month\n",
    "df_modelado[\"dia_intervalo\"] = df_modelado[\"fecha_intervalo\"].dt.day\n",
    "df_modelado[\"hora_intervalo\"] = df_modelado[\"fecha_intervalo\"].dt.hour\n",
    "df_modelado[\"minuto_intervalo\"] = df_modelado[\"fecha_intervalo\"].dt.minute\n",
    "\n",
    "df_modelado[\"edad_usuario\"] = pd.to_numeric(df_modelado[\"edad_usuario\"], errors=\"coerce\").fillna(-1).astype(int)\n",
    "\n",
    "barrios_unicos = pd.unique(df_modelado[[\"barrio_origen\", \"barrio_destino\"]].values.ravel())\n",
    "mapa_barrio = {barrio: i for i, barrio in enumerate(barrios_unicos, start=1)}\n",
    "\n",
    "df_modelado[\"barrio_origen\"] = df_modelado[\"barrio_origen\"].map(mapa_barrio)\n",
    "df_modelado[\"barrio_destino\"] = df_modelado[\"barrio_destino\"].map(mapa_barrio)\n",
    "df_modelado[\"modelo_bicicleta\"] = df_modelado[\"modelo_bicicleta\"].map({\"ICONIC\": 1, \"FIT\": 0}).astype(int)\n",
    "\n",
    "df_modelado.drop(columns=[\"hora_dia\"], inplace=True)\n",
    "df_modelado.drop(columns=[\"fecha_origen_recorrido\", \"fecha_destino_recorrido\", \"fecha_intervalo\"], inplace=True)\n",
    "\n",
    "df_modelado.to_csv(\"data/modelado/ds_modelado_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8f8fcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_recorrido                               0\n",
      "duracion_recorrido                         0\n",
      "id_estacion_origen                         0\n",
      "id_estacion_destino                        0\n",
      "id_usuario                                 0\n",
      "modelo_bicicleta                           0\n",
      "barrio_origen                              0\n",
      "barrio_destino                             0\n",
      "dia_semana                                 0\n",
      "es_finde                                   0\n",
      "estacion_del_anio                          0\n",
      "edad_usuario                               0\n",
      "a√±o_alta                                   0\n",
      "mes_alta                                   0\n",
      "genero_FEMALE                              0\n",
      "genero_MALE                                0\n",
      "genero_OTHER                               0\n",
      "usuario_registrado                         0\n",
      "zona_destino_cluster                       0\n",
      "zona_origen_cluster                        0\n",
      "cantidad_estaciones_cercanas_destino       0\n",
      "cantidad_estaciones_cercanas_origen        0\n",
      "N_arribos_intervalo                        0\n",
      "N_salidas_intervalo                        0\n",
      "a√±o_origen                                 0\n",
      "mes_origen                                 0\n",
      "dia_origen                                 0\n",
      "hora_origen                                0\n",
      "minuto_origen                              0\n",
      "segundo_origen                             0\n",
      "a√±o_destino                             3379\n",
      "mes_destino                             3379\n",
      "dia_destino                             3379\n",
      "hora_destino                            3379\n",
      "minuto_destino                          3379\n",
      "segundo_destino                         3379\n",
      "a√±o_intervalo                              0\n",
      "mes_intervalo                              0\n",
      "dia_intervalo                              0\n",
      "hora_intervalo                             0\n",
      "minuto_intervalo                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_modelado = pd.read_csv(\"data/modelado/ds_modelado_test.csv\")\n",
    "print(df_modelado.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6639b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a√±o_destino        0\n",
      "mes_destino        0\n",
      "dia_destino        0\n",
      "hora_destino       0\n",
      "minuto_destino     0\n",
      "segundo_destino    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear columna datetime de origen\n",
    "df_modelado[\"fecha_origen\"] = pd.to_datetime(dict(\n",
    "    year=df_modelado[\"a√±o_origen\"],\n",
    "    month=df_modelado[\"mes_origen\"],\n",
    "    day=df_modelado[\"dia_origen\"],\n",
    "    hour=df_modelado[\"hora_origen\"],\n",
    "    minute=df_modelado[\"minuto_origen\"],\n",
    "    second=df_modelado[\"segundo_origen\"]\n",
    "), errors=\"coerce\")  # por si hay algo raro\n",
    "\n",
    "# Sumar duraci√≥n en segundos para obtener fecha destino\n",
    "df_modelado[\"fecha_destino\"] = df_modelado[\"fecha_origen\"] + pd.to_timedelta(df_modelado[\"duracion_recorrido\"], unit=\"s\")\n",
    "\n",
    "# Extraer nueva info de fecha/hora de destino\n",
    "df_modelado[\"a√±o_destino\"] = df_modelado[\"fecha_destino\"].dt.year\n",
    "df_modelado[\"mes_destino\"] = df_modelado[\"fecha_destino\"].dt.month\n",
    "df_modelado[\"dia_destino\"] = df_modelado[\"fecha_destino\"].dt.day\n",
    "df_modelado[\"hora_destino\"] = df_modelado[\"fecha_destino\"].dt.hour\n",
    "df_modelado[\"minuto_destino\"] = df_modelado[\"fecha_destino\"].dt.minute\n",
    "df_modelado[\"segundo_destino\"] = df_modelado[\"fecha_destino\"].dt.second\n",
    "\n",
    "# Verificar que no queden nulos\n",
    "print(df_modelado[[\"a√±o_destino\", \"mes_destino\", \"dia_destino\", \"hora_destino\", \"minuto_destino\", \"segundo_destino\"]].isna().sum())\n",
    "\n",
    "# Eliminar columnas auxiliares si no las quer√©s\n",
    "df_modelado = df_modelado.drop(columns=[\"fecha_origen\", \"fecha_destino\"])\n",
    "df_modelado.to_csv(\"data/modelado/ds_modelado_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae32a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/modelado/ds_modelado_test.csv\")\n",
    "\n",
    "# Crear la columna de fecha/hora para orden temporal\n",
    "df[\"fecha_intervalo\"] = pd.to_datetime(dict(\n",
    "    year=df[\"a√±o_intervalo\"],\n",
    "    month=df[\"mes_intervalo\"],\n",
    "    day=df[\"dia_intervalo\"],\n",
    "    hour=df[\"hora_intervalo\"],\n",
    "    minute=df[\"minuto_intervalo\"]\n",
    "))\n",
    "\n",
    "# Ordenar por estaci√≥n y tiempo\n",
    "df = df.sort_values(by=[\"id_estacion_origen\", \"fecha_intervalo\"]).copy()\n",
    "\n",
    "# Agregar rolling promedio (solo usando datos anteriores, no incluye el actual)\n",
    "df[\"N_SALIDAS_PROM_2INT\"] = (\n",
    "    df.groupby(\"id_estacion_origen\")[\"N_salidas_intervalo\"]\n",
    "      .shift(1)\n",
    "      .rolling(window=2)\n",
    "      .mean()\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df[\"N_ARRIBOS_PROM_2INT\"] = (\n",
    "    df.groupby(\"id_estacion_origen\")[\"N_arribos_intervalo\"]\n",
    "      .shift(1)\n",
    "      .rolling(window=2)\n",
    "      .mean()\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Nuevas: lags de 1, 2 y 3 para salidas y arribos\n",
    "for lag in [1, 2, 3]:\n",
    "    df[f\"N_SALIDAS_LAG{lag}\"] = (\n",
    "        df.groupby(\"id_estacion_origen\")[\"N_salidas_intervalo\"].shift(lag)\n",
    "    )\n",
    "    df[f\"N_ARRIBOS_LAG{lag}\"] = (\n",
    "        df.groupby(\"id_estacion_origen\")[\"N_arribos_intervalo\"].shift(lag)\n",
    "    )\n",
    "\n",
    "# Nuevas: lags para columnas que terminan en 'destino'\n",
    "columnas_destino = [col for col in df.columns if col.endswith(\"destino\")]\n",
    "for col in columnas_destino:\n",
    "    for lag in [1, 2, 3]:\n",
    "        df[f\"{col}_LAG{lag}\"] = df.groupby(\"id_estacion_destino\")[col].shift(lag)\n",
    "\n",
    "\n",
    "df.to_csv(\"data/modelado/ds_modelado_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70ac607d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SALIDAS_PROM_2INT                           790\n",
      "N_ARRIBOS_PROM_2INT                           790\n",
      "N_SALIDAS_LAG1                                395\n",
      "N_ARRIBOS_LAG1                                395\n",
      "N_SALIDAS_LAG2                                790\n",
      "N_ARRIBOS_LAG2                                790\n",
      "N_SALIDAS_LAG3                               1185\n",
      "N_ARRIBOS_LAG3                               1185\n",
      "id_estacion_destino_LAG1                      398\n",
      "id_estacion_destino_LAG2                      796\n",
      "id_estacion_destino_LAG3                     1193\n",
      "barrio_destino_LAG1                           398\n",
      "barrio_destino_LAG2                           796\n",
      "barrio_destino_LAG3                          1193\n",
      "cantidad_estaciones_cercanas_destino_LAG1     398\n",
      "cantidad_estaciones_cercanas_destino_LAG2     796\n",
      "cantidad_estaciones_cercanas_destino_LAG3    1193\n",
      "a√±o_destino_LAG1                              398\n",
      "a√±o_destino_LAG2                              796\n",
      "a√±o_destino_LAG3                             1193\n",
      "mes_destino_LAG1                              398\n",
      "mes_destino_LAG2                              796\n",
      "mes_destino_LAG3                             1193\n",
      "dia_destino_LAG1                              398\n",
      "dia_destino_LAG2                              796\n",
      "dia_destino_LAG3                             1193\n",
      "hora_destino_LAG1                             398\n",
      "hora_destino_LAG2                             796\n",
      "hora_destino_LAG3                            1193\n",
      "minuto_destino_LAG1                           398\n",
      "minuto_destino_LAG2                           796\n",
      "minuto_destino_LAG3                          1193\n",
      "segundo_destino_LAG1                          398\n",
      "segundo_destino_LAG2                          796\n",
      "segundo_destino_LAG3                         1193\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/modelado/ds_modelado_test.csv\")\n",
    "print(df.isna().sum()[df.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc282e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SALIDAS_PROM_2INT                          286\n",
      "N_ARRIBOS_PROM_2INT                          286\n",
      "N_SALIDAS_LAG1                                21\n",
      "N_ARRIBOS_LAG1                                21\n",
      "N_SALIDAS_LAG2                                42\n",
      "N_ARRIBOS_LAG2                                42\n",
      "N_SALIDAS_LAG3                                63\n",
      "N_ARRIBOS_LAG3                                63\n",
      "id_estacion_destino_LAG1                      91\n",
      "id_estacion_destino_LAG2                     182\n",
      "id_estacion_destino_LAG3                     278\n",
      "barrio_destino_LAG1                           91\n",
      "barrio_destino_LAG2                          182\n",
      "barrio_destino_LAG3                          278\n",
      "cantidad_estaciones_cercanas_destino_LAG1     91\n",
      "cantidad_estaciones_cercanas_destino_LAG2    182\n",
      "cantidad_estaciones_cercanas_destino_LAG3    278\n",
      "a√±o_destino_LAG1                              91\n",
      "a√±o_destino_LAG2                             182\n",
      "a√±o_destino_LAG3                             278\n",
      "mes_destino_LAG1                              91\n",
      "mes_destino_LAG2                             182\n",
      "mes_destino_LAG3                             278\n",
      "dia_destino_LAG1                              91\n",
      "dia_destino_LAG2                             182\n",
      "dia_destino_LAG3                             278\n",
      "hora_destino_LAG1                             91\n",
      "hora_destino_LAG2                            182\n",
      "hora_destino_LAG3                            278\n",
      "minuto_destino_LAG1                           91\n",
      "minuto_destino_LAG2                          182\n",
      "minuto_destino_LAG3                          278\n",
      "segundo_destino_LAG1                          91\n",
      "segundo_destino_LAG2                         182\n",
      "segundo_destino_LAG3                         278\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#mes origen mayor a 8 y que sean nans\n",
    "df = df[df[\"mes_origen\"] > 8].copy()\n",
    "print(df.isna().sum()[df.isna().sum() > 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b4cb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/modelado/ds_modelado_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82e44bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agrupar columnas seg√∫n tipo de imputaci√≥n adecuada ---\n",
    "cols_promedios = [col for col in df.columns if \"PROM\" in col or \"LAG\" in col and \"N_\" in col]\n",
    "# Para los primeros valores, se llena de 0, ya que son promedios o conteos\n",
    "df[cols_promedios] = df[cols_promedios].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "cols_id = [col for col in df.columns if col.startswith(\"id_\") and \"LAG\" in col]\n",
    "cols_tiempo = [col for col in df.columns if any(t in col for t in ['a√±o_', 'mes_', 'dia_', 'hora_', 'minuto_', 'segundo_']) and 'LAG' in col]\n",
    "cols_barrio = [col for col in df.columns if \"barrio\" in col and \"LAG\" in col]\n",
    "cols_estaciones = [col for col in df.columns if \"cantidad_estaciones\" in col and \"LAG\" in col]\n",
    "#como son categor√≠as, se llenan con -1\n",
    "#en vez de poner 0 que representa una categor√≠a v√°lida, se usa -1 para indicar que no hay informaci√≥n\n",
    "\n",
    "df[cols_id + cols_barrio + cols_tiempo + cols_estaciones] = df[cols_id + cols_barrio + cols_tiempo + cols_estaciones].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbc89d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/modelado/ds_modelado_test.csv\")\n",
    "df = df[df[\"mes_origen\"] > 8].copy()\n",
    "print(df.isna().sum()[df.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d4e17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Cargar dataset ===\n",
    "df = pd.read_csv(\"data/modelado/ds_modelado_test.csv\", parse_dates=[\"fecha_intervalo\"])\n",
    "\n",
    "# === Crear columna de referencia (la estaci√≥n a la que quer√©s predecir arribos) ===\n",
    "df[\"estacion_referencia\"] = df[\"id_estacion_destino\"]\n",
    "\n",
    "# === Eliminar columnas anteriores de arribos, salidas y lags ===\n",
    "cols_a_eliminar = [col for col in df.columns if (\n",
    "    col.startswith(\"N_ARRIBOS_LAG\") or \n",
    "    col.startswith(\"N_SALIDAS_LAG\") or \n",
    "    col in [\"N_arribos_intervalo\", \"N_salidas_intervalo\"]\n",
    ")]\n",
    "df = df.drop(columns=cols_a_eliminar)\n",
    "\n",
    "# === Recalcular N_arribos_intervalo ===\n",
    "arribos = (\n",
    "    df.groupby([\"estacion_referencia\", \"fecha_intervalo\"])\n",
    "    .size()\n",
    "    .rename(\"N_arribos_intervalo\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# === Recalcular N_salidas_intervalo (asociadas a la estaci√≥n_referencia) ===\n",
    "salidas = (\n",
    "    df[df[\"id_estacion_origen\"].notna()]\n",
    "    .groupby([\"id_estacion_origen\", \"fecha_intervalo\"])\n",
    "    .size()\n",
    "    .rename(\"N_salidas_intervalo\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"id_estacion_origen\": \"estacion_referencia\"})\n",
    ")\n",
    "\n",
    "# === Merge con el dataset original ===\n",
    "df = df.merge(arribos, on=[\"estacion_referencia\", \"fecha_intervalo\"], how=\"left\")\n",
    "df = df.merge(salidas, on=[\"estacion_referencia\", \"fecha_intervalo\"], how=\"left\")\n",
    "\n",
    "# === Completar con ceros donde no hubo actividad ===\n",
    "df[\"N_arribos_intervalo\"] = df[\"N_arribos_intervalo\"].fillna(0).astype(int)\n",
    "df[\"N_salidas_intervalo\"] = df[\"N_salidas_intervalo\"].fillna(0).astype(int)\n",
    "\n",
    "# === Recalcular lags respecto a estacion_referencia ===\n",
    "df = df.sort_values([\"estacion_referencia\", \"fecha_intervalo\"])\n",
    "\n",
    "for lag in [1, 2, 3, 4, 5, 6]:\n",
    "    df[f\"N_ARRIBOS_LAG{lag}\"] = (\n",
    "        df.groupby(\"estacion_referencia\")[\"N_arribos_intervalo\"].shift(lag)\n",
    "    )\n",
    "    df[f\"N_SALIDAS_LAG{lag}\"] = (\n",
    "        df.groupby(\"estacion_referencia\")[\"N_salidas_intervalo\"].shift(lag)\n",
    "    )\n",
    "df.to_csv(\"data/modelado/ds_modelado_test_ref.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c26a9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_ARRIBOS_LAG1     394\n",
      "N_SALIDAS_LAG1     394\n",
      "N_ARRIBOS_LAG2     787\n",
      "N_SALIDAS_LAG2     787\n",
      "N_ARRIBOS_LAG3    1180\n",
      "N_SALIDAS_LAG3    1180\n",
      "N_ARRIBOS_LAG4    1573\n",
      "N_SALIDAS_LAG4    1573\n",
      "N_ARRIBOS_LAG5    1966\n",
      "N_SALIDAS_LAG5    1966\n",
      "N_ARRIBOS_LAG6    2359\n",
      "N_SALIDAS_LAG6    2359\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/modelado/ds_modelado_test_ref.csv\")\n",
    "print(df.isna().sum()[df.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ac09115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agrupar columnas seg√∫n tipo de imputaci√≥n adecuada ---\n",
    "cols_promedios = [col for col in df.columns if \"PROM\" in col or \"LAG\" in col and \"N_\" in col]\n",
    "# Para los primeros valores, se llena de 0, ya que son promedios o conteos\n",
    "df[cols_promedios] = df[cols_promedios].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "cols_id = [col for col in df.columns if col.startswith(\"id_\") and \"LAG\" in col]\n",
    "cols_tiempo = [col for col in df.columns if any(t in col for t in ['a√±o_', 'mes_', 'dia_', 'hora_', 'minuto_', 'segundo_']) and 'LAG' in col]\n",
    "cols_barrio = [col for col in df.columns if \"barrio\" in col and \"LAG\" in col]\n",
    "cols_estaciones = [col for col in df.columns if \"cantidad_estaciones\" in col and \"LAG\" in col]\n",
    "#como son categor√≠as, se llenan con -1\n",
    "#en vez de poner 0 que representa una categor√≠a v√°lida, se usa -1 para indicar que no hay informaci√≥n\n",
    "\n",
    "df[cols_id + cols_barrio + cols_tiempo + cols_estaciones] = df[cols_id + cols_barrio + cols_tiempo + cols_estaciones].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69eb9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/modelado/ds_modelado_test_ref.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e731246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/modelado/ds_modelado_test_ref.csv\")\n",
    "print(df.isna().sum()[df.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa622c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo los meses de septiembre a diciembre\n",
    "df_fin = df[df[\"mes_origen\"].isin([9, 10, 11, 12])].copy()\n",
    "# Guardar CSV\n",
    "df_fin.to_csv(\"data/modelado/ds_modelado_test_ref.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f8cbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "df_fin = pd.read_csv(\"data/modelado/ds_modelado_test_ref.csv\")\n",
    "print(df_fin.isna().sum()[df.isna().sum() > 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
